


#### 数据分析的几个硬道理：
* 成功的分析中绝大部分工作是数据预处理
* 迭代与数据科学紧密相关。经常需要对一个数据集进行多次遍历。常用的优化过程，如随机梯度下降和最大似然估计，在收敛前都需要多次扫描输入数据。
* 构建完表现卓越的模型不等于大功告成。数据科学的目标在于让数据对不懂数据科学的人有用。

由于历史的原因，探索式分析经常使用R、python，构建生产应用时，数据处理过程则完全用Java或C++重写。Java和C++缺乏交互式数据操作所需要的REPL(Read－Evaluate－Print－Loop，读取、计算、输出、循环)环境，所以不方便做探索式分析。


#### 序列化：
我们推荐在Spark中使用Kryo序列化技术。Kryo的序列化更加紧凑而且反序列化的速度快的多。要实现这个效果，需要向Kryo注册应用所需的全部定制类。开启Kryo并注册的代码：
 `val conf = new SparkConf().setAppName("myapp")`
 `conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))`
也可以通过配置文件向Kryo注册类。

#### 文件格式：
如果存储大型数据集，我们推荐使用二进制格式。Arvo和Parquet是Hadoop集群上用于存储数据的行式格式和列式格式，读入内存后可以用Avro表示。

#### MLlib:
MLlib在Spark上实现了一组机器学习算法，它强调算法的可维护性和一致性，而不是广度。

|   | 离散算法 | 连续算法 |
| ----- | :------: | :-------: |
| 监督学习 | 决策森林、朴素贝叶斯、线性支持向量机、逻辑回归、Regularized Variants|线性回归、Regularized Variants、决策森林 |
| 非监督学习 | K均值聚类 | 奇异值分解、交替最小二乘的UV分解 |
